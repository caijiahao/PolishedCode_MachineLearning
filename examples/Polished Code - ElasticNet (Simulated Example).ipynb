{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polished Code (Simulated Data Example)\n",
    "\n",
    "### Coordinate Descent Algorithm with Elastic Net Regularization\n",
    "\n",
    "#### Samir D Patel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an overview of my own implementation of an an Elastic Net Regularized, Coordinate Descent Algorithm on a simulated (randomly generated) dataset.\n",
    "\n",
    "This was done as part of my DATA 558 Machine Learning course at the University of Washington."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Only needed for IPython Notebook output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the \"Hitters\" dataset from Introduction to Statistical Learning and standardizing the predictors\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    This function loads the 'Hitters' dataset from Introduction to Statistical\n",
    "    Learning, splits the responses and predictors into X and Y respectively\n",
    "    and standardizes both X and Y.\n",
    "\n",
    "    :return X: numpy array\n",
    "        Data containing the predictors\n",
    "    :return Y: numpy array\n",
    "        Data containing the response\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    X_create = np.random.normal(loc = 1, scale = 1, size = (1, 100))\n",
    "    eps = np.random.normal(loc=0, scale=0.01,size = 100)\n",
    "    beta_c = np.array([0,1,2,3])\n",
    "\n",
    "    Y = (beta_c[0] + beta_c[1]*X_create + beta_c[2]*(X_create**2) + beta_c[3]*(X_create**3) + eps).T\n",
    "    Y = np.ravel(Y)\n",
    "\n",
    "    #Matrix of predictors\n",
    "    X = np.vstack([X_create**i for i in range(1, 4)]).T\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    Y = scaler.fit_transform(Y)\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_vars(x_data):\n",
    "    \"\"\"\n",
    "    This function takes the X dataset (predictors) as an argument and returns\n",
    "    variables containing number of columns rows, and an initialization vector \n",
    "    of beta values for the coordinate descent algorithm.\n",
    "\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :return n: numpy array\n",
    "        Data containing the number of observations/rows\n",
    "    :return p: numpy array\n",
    "        Data containing the number of predictors/columns\n",
    "    :return beta_zero: numpy array\n",
    "        A vector of zero values for initializing 'beta' in \n",
    "        the coordinate descent algorithm\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n = x_data.shape[0]\n",
    "    p = x_data.shape[1]\n",
    "    beta_zero = np.zeros(p)\n",
    "\n",
    "    return n, p, beta_zero\n",
    "\n",
    "\n",
    "def partial_min(j, beta, alpha, lamb, x_data, y_data):\n",
    "    \"\"\"\n",
    "    The function computes the solution to the partial minimization \n",
    "    problem for the L1-regularized component of the Elastic Net\n",
    "\n",
    "    :param j: int\n",
    "        Value of predictor column selected for descent\n",
    "    :param beta: numpy array\n",
    "        A vector of the beta coefficients used as input to calculate the \n",
    "        minimization of Beta at coordinate j\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty.\n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :return new_beta: numpy array\n",
    "        A vector of the updated beta coefficients after the minimization of \n",
    "        Beta at coordinate j\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x = copy.deepcopy(x_data)\n",
    "    y = copy.deepcopy(y_data)\n",
    "    p = len(x[0])\n",
    "    n = len(x)\n",
    "\n",
    "    # Split of X dataset's column j\n",
    "    x0j = np.delete(x, j, 1)\n",
    "\n",
    "    # Remaining X dataset without column j\n",
    "    xij = pd.DataFrame(x)[j]\n",
    "\n",
    "    # Beta vector deleting entry with value j\n",
    "    beta_0j = np.delete(beta, j)\n",
    "\n",
    "    c = 0.5 * (1 / n) * 2 * np.sum(np.dot(xij.T, (y - np.dot(x0j, beta_0j))))\n",
    "    a = 0.5 * (1 / n) * 2 * np.sum(xij ** 2, axis=0) + 0.5 * 2 * lamb * (1 - alpha)\n",
    "\n",
    "    if c < -lamb * alpha:\n",
    "        new_beta = (c + (lamb * alpha)) / a\n",
    "    elif c > lamb * alpha:\n",
    "        new_beta = (c - (lamb * alpha)) / a\n",
    "    else:\n",
    "        new_beta = 0\n",
    "\n",
    "    return new_beta\n",
    "\n",
    "\n",
    "def computeobj(beta, alpha, lamb, x_data, y_data):\n",
    "    \"\"\"\n",
    "    This function computes the objective function for any Beta coefficient \n",
    "    vector, with arguments for alpha, lamb and the X and Y data.\n",
    "\n",
    "    :param beta: numpy array\n",
    "        A vector of the beta coefficients used as input\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :return obj: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x = copy.deepcopy(x_data)\n",
    "    y = copy.deepcopy(y_data)\n",
    "    n = len(x)\n",
    "\n",
    "    obj = 0.5 * (1 / n) * (np.sum((y - np.dot(x, beta)) ** 2)) + 0.5 * lamb * (1 - alpha) * np.sum(\n",
    "        np.abs(beta) ** 2) + lamb * alpha * np.sum(np.abs(beta))\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def cycliccoorddescent(beta, alpha, lamb, x_data, y_data, max_iter=1000, eps=1e-7):\n",
    "    \"\"\"\n",
    "    This function implements the cyclic coordinate descent algorithm. \n",
    "    The function takes as input the initial point and the maximum number of iterations. \n",
    "    The stopping criterion is the maximum number of iterations or convergence criterion 'eps',\n",
    "    whichever comes first.\n",
    "\n",
    "    :param beta: numpy array\n",
    "        A vector of the beta coefficients used as input\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty.\n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :param max_iter: int\n",
    "        Value for setting the maximum number of iterations in the algorithm\n",
    "    :param eps: float\n",
    "        Value used as a convergence criterion to end the algorithm once the\n",
    "        coordinate descent between iterations becomes too low.\n",
    "    :return beta_out: float\n",
    "        The final calculated value of beta coefficients which minimizes\n",
    "        the objective function.\n",
    "    \"\"\"\n",
    "\n",
    "    x = copy.deepcopy(x_data)\n",
    "    y = copy.deepcopy(y_data)\n",
    "    p = len(x[0])\n",
    "    new_beta = copy.deepcopy(beta)\n",
    "    beta_out = [beta]\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    # Value set to prevent early convergence\n",
    "    bdelta = 9999\n",
    "\n",
    "    while t < (max_iter * p) and bdelta > eps:\n",
    "        j = np.remainder(t, p)\n",
    "        new_beta[j] = partial_min(j, new_beta, alpha, lamb, x, y)\n",
    "        if np.remainder(t, p) == 0:\n",
    "            beta_out.append(np.array(new_beta))\n",
    "            if t > 3:\n",
    "                bdelta = np.abs(np.linalg.norm(beta_out[-2]) - np.linalg.norm(beta_out[-1]))\n",
    "        t += 1\n",
    "\n",
    "    return beta_out\n",
    "\n",
    "\n",
    "def pickcoord(p):\n",
    "    \"\"\"\n",
    "    This function randomly samples from the set {1...d} to select a \n",
    "    coordinate in the random cyclic descent algorithm.\n",
    "\n",
    "    :param p: int\n",
    "        Number of predictors in the dataset \n",
    "    :return pick: int\n",
    "        The randomly chosen predictor use for coordinate descent\n",
    "    \"\"\"\n",
    "\n",
    "    pick = np.random.randint(p)\n",
    "\n",
    "    return pick\n",
    "\n",
    "\n",
    "def randcoorddescent(beta, alpha, lamb, x_data, y_data, max_iter=1000, eps=1e-7):\n",
    "    \"\"\"\n",
    "    This function implements the random coordinate descent algorithm. \n",
    "    The function takes as input the initial point and the maximum number of iterations. \n",
    "    The stopping criterion is the maximum number of iterations or convergence criterion 'eps',\n",
    "    whichever comes first.\n",
    "\n",
    "    :param beta: numpy array\n",
    "        A vector of the beta coefficients used as input\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty.\n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :param max_iter: int\n",
    "        Value for setting the maximum number of iterations in the algorithm\n",
    "    :param eps: float\n",
    "        Value used as a convergence criterion to end the algorithm once the\n",
    "        coordinate descent between iterations becomes too low.\n",
    "    :return beta_out: float\n",
    "        The final calculated value of beta coefficients which minimizes\n",
    "        the objective function.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x = copy.deepcopy(x_data)\n",
    "    y = copy.deepcopy(y_data)\n",
    "    p = len(x[0])\n",
    "    new_beta = copy.deepcopy(beta)\n",
    "    beta_out = [beta]\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    # Value set to prevent early convergence\n",
    "    bdelta = 9999\n",
    "\n",
    "    while t < (max_iter * p) and bdelta > eps:\n",
    "    #while t < (max_iter * p):\n",
    "        # for i in range(p):\n",
    "        j = pickcoord(p)\n",
    "        new_beta[j] = partial_min(j, new_beta, alpha, lamb, x, y)\n",
    "        if np.remainder(t, p) == 0:\n",
    "            beta_out.append(np.array(new_beta))\n",
    "            if t > 3:\n",
    "                bdelta = np.abs(np.linalg.norm(beta_out[-2]) - np.linalg.norm(beta_out[-1]))\n",
    "        t += 1\n",
    "\n",
    "    return beta_out\n",
    "\n",
    "\n",
    "def runsklelasticnetcv(alpha, x_data, y_data, descent_type):\n",
    "    \"\"\"\n",
    "    This function runs Sci-Kit Learn's ElasticNetCV running the coordinate\n",
    "    descent algorithm with cross-validation to select optimal lambda \n",
    "    (regularization penalty). Function takes  input of alpha, predictor and \n",
    "    response data, and descent type ('cyclic' or 'random')\n",
    "\n",
    "     :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "     :param descent_type: str\n",
    "        Selection of the coordinate descent algorithm type, either 'random'\n",
    "        or 'cyclic\n",
    "    :return betaskl: list of float values\n",
    "    :return lambskl: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    encv = ElasticNetCV(l1_ratio=alpha, fit_intercept=False, tol=0.000001,\n",
    "                        selection=descent_type, max_iter=10000)\n",
    "    encv.fit(x_data, y_data)\n",
    "    lambskl = encv.alpha_\n",
    "    betaskl = encv.coef_\n",
    "\n",
    "    return betaskl, lambskl\n",
    "\n",
    "\n",
    "def runsklelasticnet(lamb, alpha, x_data, y_data, descent_type):\n",
    "    \"\"\"\n",
    "    This function runs Sci-Kit Learn's ElasticNet function, running the \n",
    "    coordinate descent algorithm with input of lambda, alpha, predictor and \n",
    "    response data, and descent type ('cyclic' or 'random')\n",
    "    (regularization penalty).\n",
    "\n",
    "     :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "     :param descent_type: str\n",
    "        Selection of the coordinate descent algorithm type, either 'random'\n",
    "        or 'cyclic\n",
    "    :return betaskl: list of float values\n",
    "    :return lambskl: float\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    en = ElasticNet(alpha=lamb, l1_ratio=alpha, fit_intercept=False,\n",
    "                    selection=descent_type, tol=0.000001, max_iter=10000)\n",
    "    en.fit(x_data, y_data)\n",
    "    betaskl = en.coef_\n",
    "\n",
    "    return betaskl\n",
    "\n",
    "\n",
    "def cross_val(lamb_list, folds, x_data, y_data):\n",
    "    \"\"\"\n",
    "    This function performs cross-validation for the hand-implemented\n",
    "    coordinate descent algorithms.\n",
    "\n",
    "    :param lamb_list: list of float values\n",
    "        Values for regularization penalty to be used for cross validation.\n",
    "    :param folds:  int\n",
    "        Number of folds for K-Folds Cross Validation\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :return mse_list: list of float values\n",
    "        List output of mean-squared error values from cross-validation\n",
    "        for each lambda value, taking the the average of fold results.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.array(x_data)\n",
    "    Y = np.array(y_data)\n",
    "    beta = beta_zero\n",
    "    mse_list = []\n",
    "\n",
    "    kf = KFold(n_splits=folds, random_state=None, shuffle=False)\n",
    "\n",
    "    for lamb in lamb_list:\n",
    "\n",
    "        mse_fold = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Performing data split for fold\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            Y_train = Y_train.reshape((len(Y_train), 1))\n",
    "            Y_test = Y_test.reshape((len(Y_test), 1))\n",
    "\n",
    "            # Standardization of data after split\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            Y_train = scaler.fit_transform(Y_train)\n",
    "            Y_test = scaler.transform(Y_test)\n",
    "            Y_train = np.ravel(Y_train)\n",
    "            Y_test = np.ravel(Y_test)\n",
    "\n",
    "            # Running cyclic coord descent and calculating MSE\n",
    "            beta_temp = cycliccoorddescent(beta, 0.9, lamb, x_data=X_train, y_data=Y_train)\n",
    "            beta = beta_temp[-1]  # updating beta for warm start\n",
    "            y_hat = np.dot(X_test, beta_temp[-1].T)\n",
    "            mse_fold.append(mean_squared_error(Y_test, y_hat))\n",
    "\n",
    "        mse_list.append(np.mean(mse_fold))\n",
    "\n",
    "    return mse_list\n",
    "\n",
    "\n",
    "def runcompareCV(lamb_list, alpha, folds, X_data, Y_data):\n",
    "    \"\"\"\n",
    "    This function compares results between the hand-implemented and \n",
    "    SKLearn versions of the coordinate descent alg w/ Elastic Net regularization.\n",
    "\n",
    "    :param lamb_list: list of float values\n",
    "        Values for regularization penalty to be used for cross validation.\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param folds:  int\n",
    "        Number of folds for K-Folds Cross Validation\n",
    "    :param X_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param Y_data: numpy array\n",
    "        Data containing the response\n",
    "    :return data:  Pandas DataFrame\n",
    "        Data object containing the cross validation results.\n",
    "    :return skoptlamb: float\n",
    "        Optimal value of lambda (regularization penalty term) determined\n",
    "        by SKLearn\n",
    "    :return myoptlamb: float\n",
    "        Optimal value of lambda (regularization penalty term) determined\n",
    "        by hand-implemented algorithm.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Running hand implemented algorithm with cross-validation\n",
    "    cv_mse = cross_val(lamb_list, folds, X_data, Y_data )\n",
    "\n",
    "    # Running SKLearn algorithm with cross-validation\n",
    "    encv = ElasticNetCV(alphas=lamb_list, l1_ratio=alpha, fit_intercept=False, max_iter=10000)\n",
    "    encv.fit(X_data, Y_data)\n",
    "    skl_lambs = encv.alphas_\n",
    "    skl_mse = np.mean(encv.mse_path_, axis=1)\n",
    "    skoptlamb = encv.alpha_\n",
    "\n",
    "    # Creating dataframe with results\n",
    "    data = pd.DataFrame()\n",
    "    data['Lambda'] = lamb_list\n",
    "    data['Cyclic MSE'] = cv_mse\n",
    "    data['SKL Lambda'] = encv.alphas_[::-1]\n",
    "    data['SKL MSE'] = skl_mse[::-1]\n",
    "    data['Log Lambdas'] = np.log(lamb_list)\n",
    "    \n",
    "    # Calculating optimal lambda from hand impelmented results\n",
    "    opt_lamb = np.ravel(data[data['Cyclic MSE'] == data['Cyclic MSE'].min(0)]['Lambda'])\n",
    "    opt_lamb = opt_lamb[0]\n",
    "\n",
    "    return data, skoptlamb, opt_lamb\n",
    "\n",
    "\n",
    "def cvplot(data):\n",
    "    \"\"\"\n",
    "    This function creates a plot based on the cross-validation results\n",
    "    comparing the hand-implemented and SKLearn algorithms across varying\n",
    "    regularization penalty values.\n",
    "    \n",
    "    :param data: Pandas DataFrame\n",
    "        Data object containing cross-validation comparison from runcompareCV\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Plotting results of cross-validation comparison\n",
    "    plt.figure(figsize=(30, 10));\n",
    "    plt.plot(data['Log Lambdas'], data['Cyclic MSE'], label=\"Cyclic\");\n",
    "    plt.plot(data['Log Lambdas'], data['SKL MSE'], 'o', label=\"SKLearn_ELCV\");\n",
    "    plt.legend();\n",
    "    plt.ylabel(\"Mean Squared Error\", fontsize=30);\n",
    "    plt.xlabel(\"Log Lambdas\", fontsize=30);\n",
    "    plt.title(\"Log Lambda vs Mean Squared Error from Cross Validation\", fontsize=40);\n",
    "    plt.xticks(fontsize=30);\n",
    "    plt.yticks(fontsize=30);\n",
    "    plt.legend(fontsize=30);\n",
    "\n",
    "    \n",
    "def calc_obj_val(beta_vals, alpha, lamb, x_data, y_data):\n",
    "    \"\"\"\n",
    "    This function calculates a list of objective values across the \n",
    "    iterations of the coordinate descent algorithm.\n",
    "\n",
    "    :param beta_vals: numpy array\n",
    "        A vector of the beta coefficients used as input\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :return obj_vals: list of float values\n",
    "        The calculated objective function values throughout the coordinate\n",
    "        descent (across all iterations)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    obj_vals = []\n",
    "\n",
    "    for i in range(len(beta_vals)):\n",
    "        objv = computeobj(beta_vals[i], alpha, lamb, x_data, y_data)\n",
    "        obj_vals.append(objv)\n",
    "\n",
    "    return obj_vals\n",
    "\n",
    "\n",
    "def objvals(alpha, lamb, x_data, y_data, beta_cyc_vals, beta_rand_vals):\n",
    "    \"\"\"\n",
    "    This function outputs the list of objective values for hand-implemented\n",
    "    cyclic and random coordinate descent algorithms, along with iteration\n",
    "    counts for each.\n",
    "\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :param beta_cyc_vals: numpy array\n",
    "        Beta coefficient vectors for the iterations from the cyclic coordinate descent\n",
    "    :param beta_rand_vals: numpy array\n",
    "        Beta coefficient vectors for the iterations from the random coordinate descent\n",
    "    :return cyc_obj_vals: list of float values\n",
    "        The calculated objective function values throughout the cyclic\n",
    "        coordinate descent (across all iterations)\n",
    "    :return rand_obj_vals: list of float values\n",
    "        The calculated objective function values throughout the random\n",
    "        coordinate descent (across all iterations)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    cyc_obj_vals = calc_obj_val(beta_cyc_vals, alpha, lamb, x_data, y_data)\n",
    "    rand_obj_vals = calc_obj_val(beta_rand_vals, alpha, lamb, x_data, y_data)\n",
    "\n",
    "    t_cyc_count = np.arange(len(cyc_obj_vals))\n",
    "    t_rand_count = np.arange(len(rand_obj_vals))\n",
    "\n",
    "    return cyc_obj_vals, rand_obj_vals, t_cyc_count, t_rand_count\n",
    "\n",
    "\n",
    "def objvalsplot(alpha, lamb, x_data, y_data, beta_cyc_vals, beta_rand_vals):\n",
    "    \"\"\"\n",
    "    This function creates a plot of the objective values vs iteration counts\n",
    "    for hand-implemented cyclic and random coordinate descent algorithms \n",
    "\n",
    "    :param alpha: float\n",
    "        Value for controlling the ElasticNet's L1_ratio where alpha = 0 is a full\n",
    "        L2 penalty and alpha = 1 is a full L1 penalty.  Values between represent a\n",
    "        combination of L1 and L2 penalty. \n",
    "    :param lamb:  float\n",
    "        Value of regularization penalty to apply to model\n",
    "    :param x_data: numpy array\n",
    "        Data containing the predictors\n",
    "    :param y_data: numpy array\n",
    "        Data containing the response\n",
    "    :param beta_cyc_vals: numpy array\n",
    "        Beta coefficient vectors for the iterations from the cyclic coordinate descent\n",
    "    :param beta_rand_vals: numpy array\n",
    "        Beta coefficient vectors for the iterations from the random coordinate descent\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating objective values and iteration counts for cyclic and random\n",
    "    cyc_obj_vals, rand_obj_vals, t_cyc_count, t_rand_count = objvals(alpha, lamb, x_data, \n",
    "                                                                     y_data, beta_cyc_vals, beta_rand_vals)\n",
    "\n",
    "    # Plotting results of objective values across iteration for cyclic and random\n",
    "    plt.figure(figsize=(15, 7));\n",
    "    plt.plot(t_cyc_count, cyc_obj_vals, label=\"Cyclic\");\n",
    "    plt.plot(t_rand_count, rand_obj_vals, \"+\", label=\"Random\");\n",
    "    plt.legend();\n",
    "    plt.ylabel(\"Objective Value\", fontsize=20);\n",
    "    plt.xlabel(\"Iteration Count (t)\", fontsize=20);\n",
    "    plt.title(\"Iteration Count (t) vs Objective Values\", fontsize=25);\n",
    "    plt.xticks(fontsize=20);\n",
    "    plt.yticks(fontsize=20);\n",
    "    plt.legend(fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 1: \"Hitters\" data set (real world example)\n",
    "\n",
    "##### The example we will go through uses a dataset from the real-world, \"Hitters\", from Introduction to Statistical Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samir\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Samir\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Initialization of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, p, beta_zero = init_vars(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating list of lambda (regularization penalty) values to use for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb_list = [10**k for k in range(-7, 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Running own implementation of cross-validation using K-Folds method and comparing to the cross-validation results of _ElasticNetCV_ from Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvdata, skopt, myoptlamb = runcompareCV(lamb_list, 0.9, 3, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Optimal Lambda (Regularization parameter) - My Cyclic Coordinate Descent with Elastic Net after Cross Validation\n",
      " \n",
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print('Optimal Lambda (Regularization parameter) - My Cyclic Coordinate Descent with Elastic Net after Cross Validation')\n",
    "print(' ')\n",
    "print(myoptlamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculation and comparison of objective values vs iteration count for both hand implemented cyclic and random coordinate descent algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Beta Coefficients - My Cyclic Coordinate Descent with Elastic Net using Optimal Lambda\n",
      " \n",
      "[ 0.03607304  0.17866758  0.79507307]\n"
     ]
    }
   ],
   "source": [
    "beta_cyc_opt = cycliccoorddescent(beta_zero, 0.9, myoptlamb, X, Y, max_iter = 300)\n",
    "print(' ')\n",
    "print('Beta Coefficients - My Cyclic Coordinate Descent with Elastic Net using Optimal Lambda')\n",
    "print(' ')\n",
    "print(beta_cyc_opt[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Beta Coefficients - My Random Coordinate Descent with Elastic Net using Optimal Lambda\n",
      " \n",
      "[ 0.01199575  0.0012578   0.99856505]\n"
     ]
    }
   ],
   "source": [
    "beta_rand_opt = randcoorddescent(beta_zero, 0.9, myoptlamb, X, Y, max_iter = 300)\n",
    "print(' ')\n",
    "print('Beta Coefficients - My Random Coordinate Descent with Elastic Net using Optimal Lambda')\n",
    "print(' ')\n",
    "print(beta_rand_opt[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of objective values across the iterations of the cyclic and random descent algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5QAAAHUCAYAAABF8WcNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUEqSJEmSWmJCKUmSJElqyf8Hf4XdmD7gWbcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bf88c3e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objvalsplot(0.9, myoptlamb, X, Y, beta_cyc_opt, beta_rand_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the results above, we see that convergence happens relatively quickly for both the cyclic and random coordinate descent algorithms which also line up reasonably well in respect to one another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
